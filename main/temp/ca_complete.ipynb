{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65f2d8c0-6a5c-4280-a981-804b76ffa660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from shapely.geometry import Point, box\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c2dbc33-bfa6-4512-a9de-b466bba4fbfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 读取堤坝数据\n",
    "df_dams = pd.read_csv('data/CA_df_dam.csv')\n",
    "df_dams['date'] = pd.to_datetime(df_dams['date'])\n",
    "\n",
    "# 定义时间窗口和空间窗口\n",
    "time_window = timedelta(days=7)\n",
    "space_buffer = 0.1\n",
    "\n",
    "# 创建GeoDataFrame\n",
    "geometry = [Point(xy) for xy in zip(df_dams['longitude'], df_dams['latitude'])]\n",
    "gdf_dams = gpd.GeoDataFrame(df_dams, geometry=geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c7307fc-763c-45e6-a7d9-9555227a1655",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 合并堤坝数据\n",
    "def merge_dam_data(gdf, time_window, space_buffer):\n",
    "    merged_data = []\n",
    "    \n",
    "    while not gdf.empty:\n",
    "        # 取第一个点作为参考点\n",
    "        ref_point = gdf.iloc[0]\n",
    "        ref_date = ref_point['date']\n",
    "        \n",
    "        # 创建时间和空间范围\n",
    "        time_range = (gdf['date'] >= ref_date - time_window) & (gdf['date'] <= ref_date + time_window)\n",
    "        space_range = gdf.geometry.apply(lambda x: x.within(ref_point.geometry.buffer(space_buffer)))\n",
    "        \n",
    "        # 获取在范围内的所有点\n",
    "        in_range = gdf[time_range & space_range]\n",
    "        \n",
    "        # 创建合并后的空间范围和时间范围\n",
    "        minx, miny, maxx, maxy = in_range.total_bounds\n",
    "        merged_bbox = box(minx, miny, maxx, maxy)\n",
    "        merged_start_date = in_range['date'].min()\n",
    "        merged_end_date = in_range['date'].max()\n",
    "        \n",
    "        # 添加到合并后的数据\n",
    "        merged_data.append({\n",
    "            'bbox': merged_bbox,\n",
    "            'start_date': merged_start_date,\n",
    "            'end_date': merged_end_date\n",
    "        })\n",
    "        \n",
    "        # 移除已经合并的点\n",
    "        gdf = gdf.drop(in_range.index)\n",
    "    \n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c084df32-2b9d-40d1-908b-02131044e8fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_data = merge_dam_data(gdf_dams, time_window, space_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8b4964d-ba18-4f57-b29a-dbb22874711f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bbox': <POLYGON ((-118.136 35.933, -118.136 36.028, -118.206 36.028, -118.206 35.93...>, 'start_date': Timestamp('2020-08-22 00:00:00'), 'end_date': Timestamp('2020-08-22 00:00:00')}\n",
      "{'bbox': <POLYGON ((-118.167 35.892, -118.167 35.927, -118.189 35.927, -118.189 35.89...>, 'start_date': Timestamp('2020-08-22 00:00:00'), 'end_date': Timestamp('2020-08-22 00:00:00')}\n",
      "{'bbox': <POLYGON ((-118.136 35.933, -118.136 36.029, -118.202 36.029, -118.202 35.93...>, 'start_date': Timestamp('2016-07-15 00:00:00'), 'end_date': Timestamp('2016-07-15 00:00:00')}\n",
      "{'bbox': <POLYGON ((-118.165 35.883, -118.165 35.932, -118.194 35.932, -118.194 35.88...>, 'start_date': Timestamp('2016-07-15 00:00:00'), 'end_date': Timestamp('2016-07-15 00:00:00')}\n",
      "{'bbox': <POLYGON ((-118.132 35.933, -118.132 36.028, -118.197 36.028, -118.197 35.93...>, 'start_date': Timestamp('2013-04-20 00:00:00'), 'end_date': Timestamp('2013-04-20 00:00:00')}\n",
      "{'bbox': <POLYGON ((-118.165 35.882, -118.165 35.927, -118.194 35.927, -118.194 35.88...>, 'start_date': Timestamp('2013-04-20 00:00:00'), 'end_date': Timestamp('2013-04-20 00:00:00')}\n",
      "{'bbox': <POLYGON ((-118.134 35.941, -118.134 36.03, -118.206 36.03, -118.206 35.941,...>, 'start_date': Timestamp('2020-06-15 00:00:00'), 'end_date': Timestamp('2020-06-15 00:00:00')}\n",
      "{'bbox': <POLYGON ((-118.167 35.923, -118.167 35.927, -118.168 35.927, -118.168 35.92...>, 'start_date': Timestamp('2020-06-15 00:00:00'), 'end_date': Timestamp('2020-06-15 00:00:00')}\n",
      "{'bbox': <POLYGON ((-118.132 35.934, -118.132 36.029, -118.191 36.029, -118.191 35.93...>, 'start_date': Timestamp('2018-06-15 00:00:00'), 'end_date': Timestamp('2018-06-15 00:00:00')}\n",
      "{'bbox': <POLYGON ((-118.166 35.892, -118.166 35.932, -118.189 35.932, -118.189 35.89...>, 'start_date': Timestamp('2018-06-15 00:00:00'), 'end_date': Timestamp('2018-06-15 00:00:00')}\n",
      "{'bbox': <POLYGON ((-118.132 35.892, -118.132 36.029, -118.206 36.029, -118.206 35.89...>, 'start_date': Timestamp('2022-06-15 00:00:00'), 'end_date': Timestamp('2022-06-15 00:00:00')}\n"
     ]
    }
   ],
   "source": [
    "# 打印合并后的数据\n",
    "for data in merged_data:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eaf40c0-73f2-45de-aec0-95097f1a64b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_satellite_images(m2m, start_date, end_date, bbox):\n",
    "    spatial_filter = {\n",
    "        'filterType': 'mbr',\n",
    "        'lowerLeft': {'longitude': bbox[0], 'latitude': bbox[1]},\n",
    "        'upperRight': {'longitude': bbox[2], 'latitude': bbox[3]},\n",
    "    }\n",
    "    temporal_filter = {\n",
    "        'startDate': start_date.strftime('%Y-%m-%d'),\n",
    "        'endDate': end_date.strftime('%Y-%m-%d')\n",
    "    }\n",
    "    \n",
    "    scenes = m2m.searchScenes(datasetName='landsat_etm_c2_l2', \n",
    "                              spatialFilter=spatial_filter, \n",
    "                              temporalFilter=temporal_filter,\n",
    "                              maxCC=10, \n",
    "                              maxResults=100)\n",
    "    return scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c888d3a-8d57-486c-83ee-eb1bcdb55b93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from M2M_package import api\n",
    "\n",
    "# 执行查询和下载\n",
    "username = 'zk2086'\n",
    "password = 'Wohechunge2002@'\n",
    "token = \"Yfq@gleb2SsNf4VjuwFIh3@hmZV5DA_5UR1gWrx6Yl4hQa4p5YL7ds!fhkssxorJ\"\n",
    "m2m = api.M2M(username, password) # Instantiate the API class and it will prompt you to enter the credentials.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "411b5517-bc91-4755-868a-b47a5ca619aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:M2M.searchScenes - more hits 1138870 than returned records 100, consider increasing maxResults parameter.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo scenes found for this query\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m query_and_download(merged_data, m2m)\n",
      "Cell \u001b[0;32mIn[15], line 12\u001b[0m, in \u001b[0;36mquery_and_download\u001b[0;34m(merged_data, m2m)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scenes:\n\u001b[1;32m     11\u001b[0m     scene_ids \u001b[38;5;241m=\u001b[39m [scenes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentityId\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m scene \u001b[38;5;129;01min\u001b[39;00m scenes]\n\u001b[0;32m---> 12\u001b[0m     download_metadata \u001b[38;5;241m=\u001b[39m m2m\u001b[38;5;241m.\u001b[39mretrieveScenes(datasetName\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlandsat_etm_c2_l2\u001b[39m\u001b[38;5;124m'\u001b[39m, scenes\u001b[38;5;241m=\u001b[39mscenes)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# 保存图像\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m scene \u001b[38;5;129;01min\u001b[39;00m download_metadata:\n",
      "File \u001b[0;32m~/codebase/BEAVER/code/beaver-project/main/M2M_package/api.py:230\u001b[0m, in \u001b[0;36mM2M.retrieveScenes\u001b[0;34m(self, datasetName, scenes, filterOptions, label)\u001b[0m\n\u001b[1;32m    228\u001b[0m                 downloadIds \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m downloadUpdate\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m         download_scenes(requestResults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavailableDownloads\u001b[39m\u001b[38;5;124m'\u001b[39m], downloadMeta)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM2M.retrieveScenes - No download options found\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/codebase/BEAVER/code/beaver-project/main/M2M_package/downloader.py:103\u001b[0m, in \u001b[0;36mdownload_scenes\u001b[0;34m(downloads, downloadMeta)\u001b[0m\n\u001b[1;32m    101\u001b[0m     downloadMeta[idD]\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m: url, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_path\u001b[39m\u001b[38;5;124m'\u001b[39m: local_path})\n\u001b[1;32m    102\u001b[0m finished \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mas_completed(futures):\n\u001b[1;32m    104\u001b[0m     finished \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    105\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdownload_scenes - download finished by \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m scenes\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(finished,\u001b[38;5;28mlen\u001b[39m(futures)))\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/concurrent/futures/_base.py:243\u001b[0m, in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wait_timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[1;32m    240\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) futures unfinished\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    241\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[0;32m--> 243\u001b[0m waiter\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mwait(wait_timeout)\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m waiter\u001b[38;5;241m.\u001b[39mlock:\n\u001b[1;32m    246\u001b[0m     finished \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39mfinished_futures\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/threading.py:622\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    620\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 622\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cond\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def query_and_download(merged_data, m2m):\n",
    "    for data in merged_data:\n",
    "        start_date = data['start_date']\n",
    "        end_date = data['end_date']\n",
    "        bbox = data['bbox'].bounds\n",
    "        \n",
    "        scenes = query_satellite_images(m2m, start_date, end_date, bbox)\n",
    "        \n",
    "        # 下载对应的场景\n",
    "        if scenes:\n",
    "            scene_ids = [scenes['results'][0]['entityId'] for scene in scenes]\n",
    "            download_metadata = m2m.retrieveScenes(datasetName='landsat_etm_c2_l2', scenes=scenes)\n",
    "            # 保存图像\n",
    "            for scene in download_metadata:\n",
    "                m2m.download(scene['entityId'])\n",
    "        else:\n",
    "            print(\"No scenes found for this query\")\n",
    "\n",
    "query_and_download(merged_data, m2m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4677940-596f-4b2f-8aba-c107292bd1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
